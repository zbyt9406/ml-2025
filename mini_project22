# ğŸ¤– Machine Learning Mini-Project 2: Probabilistic Models & Decision Trees

This repository contains the **second mini-project** for the **Machine Learning (Spring 2025)** course at **K. N. Toosi University of Technology**.  
It covers **probabilistic classifiers**, **instance-based learning**, and **tree-based models** through three practical questions.

---

## ğŸ“ Project Structure

â”œâ”€â”€ Question_1_Bayesian_Spam_Filtering/
â”‚ â””â”€â”€ Naive Bayes for SMS spam classification
â”œâ”€â”€ Question_2_KNN_on_MNIST/
â”‚ â””â”€â”€ K-Nearest Neighbors for handwritten digit recognition
â”œâ”€â”€ Question_3_Decision_Tree_for_Sales_Analysis/
â”‚ â””â”€â”€ Decision Tree for analyzing clothing sales data



---

## ğŸ“¨ Question 1: Spam Filtering with Naive Bayes

Applies **Bayesian classifiers** to detect spam messages in an SMS dataset, aiming to compare theoretical models and implement a Naive Bayes classifier **from scratch**.

### ğŸ” Key Tasks

- **ğŸ“˜ Theoretical Comparison**  
  Detailed comparison between **Naive Bayes** and **Optimal Bayes**, highlighting key differences.

- **ğŸ§  Model Selection**  
  Justification for choosing an appropriate variant of Naive Bayes (e.g., **Multinomial**, **Bernoulli**, or **Gaussian**) based on the dataset.

- **ğŸ› ï¸ Custom Implementation**  
  Naive Bayes implemented from scratch (without libraries like `scikit-learn`).

- **âš–ï¸ Comparative Analysis**  
  - Re-implementation using `scikit-learn` models  
  - Performance comparison via **confusion matrix**, **precision**, **recall**

- **ğŸš¨ Risk-Aware Decision Making**  
  Bayes decision rule modified to incorporate **asymmetric misclassification costs** (e.g., spam vs. legitimate messages).

---

## âœï¸ Question 2: Handwritten Digit Recognition with KNN

Uses the **K-Nearest Neighbors (KNN)** algorithm to classify handwritten digits from the **MNIST** dataset.

### ğŸ” Key Tasks

- **ğŸ§¹ Data Normalization**  
  - 10,000-sample subset selected  
  - Normalized using **StandardScaler** or **MinMaxScaler** (with reasoning)

- **ğŸ”§ Hyperparameter Tuning**  
  - KNN trained with various **k** values  
  - Model accuracy plotted vs. k to determine the optimal setting

- **ğŸ“‰ Dimensionality Reduction with PCA**  
  - **Principal Component Analysis (PCA)** applied to reduce feature space  
  - Model tested on varying numbers of components  
  - Visualized trade-offs between **accuracy** and **dimensionality**

---

## ğŸ“ˆ Question 3: Sales Analysis with Decision Trees

Solves a **business analytics** task using Decision Trees to identify key features impacting clothing sales volume.

### ğŸ” Key Tasks

- **ğŸ§¹ Data Preprocessing**  
  - 400 records with 10 features  
  - Handling **missing values**, **duplicates**, and **categorical encoding**  
  - Sales values binned into **Low / Medium / High** categories

- **ğŸ“Š Feature Analysis**  
  - **Correlation matrix** to study feature-target relationships  
  - Manual computation of **entropy** and **information gain** for split selection

- **ğŸŒ² Model Training & Optimization**  
  - Explains **pruning** and its benefits  
  - Uses `GridSearchCV` to tune hyperparameters

- **ğŸ§ª Evaluation & Interpretation**  
  - Final tree **visualized** and analyzed  
  - Checks for **overfitting/underfitting**  
  - Evaluated using **confusion matrix** and other metrics

---

## ğŸ“Œ Summary

This mini-project demonstrates:
- Implementation of models **from scratch**
- Practical experience with **Scikit-learn**
- Understanding of **Bayesian theory**, **KNN behavior**, and **Decision Tree splitting**
- Application of **real-world datasets** and performance evaluation

---

## ğŸ§‘â€ğŸ’» Contributors

- [Your Name Here]

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the `LICENSE` file for details.

